---
title: Udacity の "Intro to Machine Learning" で機械学習に入門した
date: 2018-02-07T22:24:49-08:00
readmore: true
---

去年にはじめた Udacity の [Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120) をようやく終わらせた。

Udacity は Coursera のような MOOC の一種で、今は有料の [Nanodegree](https://www.udacity.com/nanodegree) と呼ばれるプログラムに注力しているように見えるけれど、無料のコースも色々とある。

Intro to Machine Learning のことは [Machine Learning in a Year](https://medium.com/learning-new-stuff/machine-learning-in-a-year-cdb0b0ebd29c) で知った。[Coursera の Machine Learning](https://www.coursera.org/learn/machine-learning) に挫折したという著者が

> If I could go back in time, I’d choose Udacity’s Intro to Machine Learning, as it’s easier and uses Python and Scikit Learn. This way, we would have gotten our hands dirty as soon as possible, gained confidence, and had more fun.

と Udacity のコースを紹介しているのをみて、Coursera のコースに数回挑戦しては完走せずに挫折していた私でも、これならなんとかなるかもと思って挑戦してみた。

### 良いところ

コース全体は Python をプログラミング言語に、scikit-learn をライブラリに、色々な機械学習のアルゴリズム (ただし深層学習以前のもの) を使ってみる、というところに重きがおかれている。

理解度は、動画の途中に挟まるクイズと、その後の「ミニプロジェクト」と呼ばれる、実際に Python でコードを書いてみるところで、ある程度わかっていないと先に進めないようになっている。とはいえどちらも難易度はそこまで高くない。

Udacity 全体の傾向なのか、このコースだけなのか、動画は数分程度の短いものが多いので、私は昼食をひっそり早めに食べて、会社で黙々とやったりもしていた。

講師が二人いて、途中でバトンタッチしながら進むのも、ちょっとしたアクセントになって良い感じだった。

### 良くないところ

コースは数年前に作られたものなので、Python は 2.x 系だし、Jupyter Notebook も登場しない。

また、ファイナルプロジェクトについては、動画の中では提出すれば採点されそうな雰囲気を出しているけど、フォーラムによると[提出する場所はもうなく、採点はされない](https://discussions.udacity.com/t/finished-final-project-but-how-do-i-submit-it-for-review/439349)らしい。ここらへんは、最初にふれた Nanodegree だとチューターがつくのかもしれない。

scikit-learn も、最新バージョン向けにちょっと書き換えが必要だったりするけれど、ここはミニプロジェクトの直前に説明があったりするので、そこまでは困らなかった。

<!--more-->

### 目次

都合で一年近くかけてしまって、だいぶ忘れかけているので、自分向けに目次を書いておく。

1. Welcome to Machine Learning
   * コースの紹介。最後の Prerequisites に、Udacity のなかの統計関係のコースへのリンクがある。私はとっていないけど。
2. Naive Bayes
   * 最初のユニットなので「Supervised (教師つき) が意味するところとは」「Training (学習) と Testing でなぜデータを分けるのか」みたいな、ナイーブベイズ以前の話もここに入っている。
3. SVM
   * サポートベクターマシン
4. Decision Tree
   * 決定木
5. Choose Your own Algorithm
   * K-nearest Neighbors, Ada Boost, Random Forest をそれぞれ使ってみて、良いものを探そう
6. Datasets and Questions
   * Enron の電子メールデータをさわってみる
7. Regressions
   * 線形回帰など
8. Outliers
   * データセットから外れ値を削除する
9. Clustering
   * Unsupervised Learning (教師なし学習) についてふれたあとに、K-means など
10. Feature Scaling
   * 特徴量は正規化しましょう、的なはなし
11. Text Learning
   * Bag of Words など
12. Feature Selection
   * 特徴量のえらびかた
13. PCA
   * Principal Component Analysis (主成分分析)
14. Validation
   * Cross Validation
15. Evaluation Metrics
   * Precision と Recall
16. Trying It All Together
   * まとめ。Summary という二番目の動画が今まで学んだものの関係性を図にしてくれていて良い。
17. Final Project

### 次に勉強するもの

深層学習については『ゼロから作るDeep Learning』を買ったまま積んでいて、一方で [fast.ai](http://www.fast.ai/) も気になっている。ただ、最近に関係なく読んだ [James Clear という人のインタビュー](https://blog.rescuetime.com/james-clear/) の

> While it’s important to know as much as possible before you start, real learning comes from experience. From trial and error and trying different methods to see what works best for you.

この一節にちょっと思いあたるところがあるので、まずは scikit-learn だけで何か作った方がいいのかもしれない。
